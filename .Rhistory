title: "Reproducible Research: Peer Assessment 1"
output:
html_document:
keep_md: true
---
## Loading and preprocessing the data
The following chunks of R code assume that the activity data set is unzipped as activity.csv in the present working directory.
```{r, echo=TRUE}
library(sqldf)
library(ggplot2)
dat <- read.csv("activity.csv")
```
## What is mean total number of steps taken per day?
### 1. Calculate the total number of steps taken per day
The mean total number of steps taken per day is 10766.19.
```{r, echo=TRUE}
sql_statement <- "SELECT 1.0 * SUM(DayTotalSteps)/COUNT(1) AS [Mean total number of steps taken per day] FROM (SELECT SUM(steps) as DayTotalSteps FROM dat WHERE steps IS NOT NULL GROUP BY date)"
MeanTotalStepsPerDay <- sqldf(sql_statement)
```
### 2. Make a histogram of the total number of steps taken each day
To further address this question, we construct a histogram of the total number of steps taken each day and report the mean and median of the total number of steps taken per day on the plot. This is exploratory, so we will leave the plot's "window dressing" for another time. (At that point, we'll also remove things like the hardcoded values.)
```{r, echo=TRUE}
sql_statement <- "SELECT SUM(steps) as DayTotalSteps FROM dat WHERE steps IS NOT NULL GROUP BY date"
hist_dat <- sqldf(sql_statement)
ggplot(data = hist_dat, aes(hist_dat$DayTotalSteps)) + geom_histogram() + geom_vline(xintercept = 10766.19) + annotate("text", x = 10700, y = 9.4, label = "Mean = 10766.19, Median = 10765")
```
### 3. Calculate and report the mean and median of the total number of steps taken per day
The mean of the total number of steps taken per day is 10766.19.
```{r, echo=TRUE}
MeanTotalStepsPerDay
```
The median of the total number of steps taken per day is 10765.
```{r, echo=TRUE}
median(hist_dat$DayTotalSteps)
```
## What is the average daily activity pattern?
For this section of the project, we continue to ignore NA values (since the following involves imputing those missing values). Again, plot "window dressing" is left for another time.
### 1. Make a time series plot (i.e. ?????????? = "????") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)
```{r, echo=TRUE}
sql_statement <- "SELECT 1.0 * SUM(steps)/COUNT(1) AS [IntervalMeanSteps], interval FROM dat WHERE steps IS NOT NULL GROUP BY interval"
plot_dat <- sqldf(sql_statement)
ggplot(data = plot_dat, aes(x = plot_dat$interval, y = plot_dat$IntervalMeanSteps, group = 1)) + geom_line()
```
### 2. Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?
Interval 835 contains the maximum number of steps, on average, across all the days in the dataset: 206.1698 steps.
```{r, echo=TRUE}
sql_statement <- "SELECT interval AS [Interval of Max Mean Steps], IntervalMeanSteps AS [Max Mean Steps] FROM plot_dat WHERE IntervalMeanSteps = (SELECT MAX(IntervalMeanSteps) from plot_dat)"
sqldf(sql_statement)
```
## Imputing missing values
There are a number of days/intervals where there are missing values (coded as ????). The presence of missing days may introduce bias into some calculations or summaries of the data.
### 1. Calculate and report the total number of missing values in the dataset
```{r, echo=TRUE}
sql_statement <- "SELECT COUNT(1) AS [Number of NA Values] FROM dat WHERE steps IS NULL"
sqldf(sql_statement)
```
### 2. Devise a strategy for filling in all of the missing values in the dataset
Here, we will use the suggested strategy of replacing NA values with the mean number of steps for the corresponding interval. The reason for this choice over replacing with a day's mean is that some days consist entirely of NA data points. In the future, we may use a function of surrounding time intervals to calculate a particular NA's replacement value.
```{r, echo=TRUE}
sql_statement <- "SELECT interval, 1.0 * SUM(steps)/COUNT(1) MeanSteps FROM dat WHERE steps IS NOT NULL GROUP BY interval"
IntervalMeanSteps <- sqldf(sql_statement)
```
### 3. Create a new dataset that is equal to the original dataset but with the missing data filled in
```{r, echo=TRUE}
sql_statement <- "SELECT CASE WHEN steps IS NULL THEN IntervalMeanSteps.MeanSteps ELSE steps END AS StepsImpute, dat.date, dat.interval FROM dat LEFT JOIN IntervalMeanSteps ON dat.interval = IntervalMeanSteps.interval"
impute_dat <- sqldf(sql_statement)
```
A quick check of the original and new data sets:
```{r, echo=TRUE}
head(dat)
head(impute_dat)
```
### 4. Make a histogram of the total number of steps taken each day
We'll repeat some of the steps used above, generating the histogram for the data set with imputed values and reporting the new mean and median on the plot. The mean hasn't changed; however, the median is now equal to the mean and the shape of the histogram has changed (e.g., near the mode). In the days ahead, this calculation will be checked for correctness via alternate means.
```{r, echo=TRUE}
sql_statement <- "SELECT 1.0 * SUM(DayTotalImputeSteps)/COUNT(1) AS [Mean total number of steps (with imputation) taken per day] FROM (SELECT SUM(StepsImpute) as DayTotalImputeSteps FROM impute_dat GROUP BY date)"
MeanTotalImputeStepsPerDay <- sqldf(sql_statement)
MeanTotalImputeStepsPerDay
MedianTotalImputeStepsPerDay <- median(sqldf("SELECT SUM(StepsImpute) as DayTotalImputeSteps FROM impute_dat GROUP BY date")$DayTotalImputeSteps)
MedianTotalImputeStepsPerDay
sql_statement <- "SELECT SUM(StepsImpute) as DayTotalImputeSteps FROM impute_dat GROUP BY date"
hist_dat <- sqldf(sql_statement)
ggplot(data = hist_dat, aes(hist_dat$DayTotalImputeSteps)) + geom_histogram() + geom_vline(xintercept = 10766.19) + annotate("text", x = 10700, y = 12.4, label = "Mean = Median = 10766.19")
```
## Are there differences in activity patterns between weekdays and weekends?
### 1. Create a new factor variable in the dataset with two levels ?? ?eekday?? and ?eekend?? indicating whether a given date is a weekday or weekend day.
```{r, echo=TRUE}
impute_dat$date <- as.Date(impute_dat$date)
weekday <- c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday')
impute_dat$isWeekday <- factor((weekdays(impute_dat$date) %in% weekday), levels = c(FALSE, TRUE), labels = c('weekend', 'weekday'))
head(impute_dat)
```
### 2. Make a panel plot
In this step we make a panel plot containing a time series plot of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis). There appears to be a difference in the subjects activity between weekday and weekend days. The large weekday peak near interval 860 compared to the remaining day's lower degree of activity contrasts to the more uniform nature of the weekend activity. There doesn't appear to be as clear a maximum for weekend intervals, when inspecting visually.
```{r, echo=TRUE}
sql_statement <- "SELECT 1.0 * SUM(StepsImpute)/COUNT(1) AS [IntervalMeanImputeSteps], interval, isWeekday FROM impute_dat GROUP BY interval, isWeekday"
plot_dat <- sqldf(sql_statement)
ggplot(data = plot_dat, aes(x = plot_dat$interval, y = plot_dat$IntervalMeanImputeSteps, group = 1)) + geom_line(color="firebrick",lwd = 1) + facet_wrap(~isWeekday, ncol = 1)
```
install.packages("sqldf")
---
title: "Reproducible Research: Peer Assessment 1"
output:
html_document:
keep_md: true
---
## Loading and preprocessing the data
The following chunks of R code assume that the activity data set is unzipped as activity.csv in the present working directory.
```{r, echo=TRUE}
library(sqldf)
library(ggplot2)
dat <- read.csv("activity.csv")
```
## What is mean total number of steps taken per day?
### 1. Calculate the total number of steps taken per day
The mean total number of steps taken per day is 10766.19.
```{r, echo=TRUE}
sql_statement <- "SELECT 1.0 * SUM(DayTotalSteps)/COUNT(1) AS [Mean total number of steps taken per day] FROM (SELECT SUM(steps) as DayTotalSteps FROM dat WHERE steps IS NOT NULL GROUP BY date)"
MeanTotalStepsPerDay <- sqldf(sql_statement)
```
### 2. Make a histogram of the total number of steps taken each day
To further address this question, we construct a histogram of the total number of steps taken each day and report the mean and median of the total number of steps taken per day on the plot. This is exploratory, so we will leave the plot's "window dressing" for another time. (At that point, we'll also remove things like the hardcoded values.)
```{r, echo=TRUE}
sql_statement <- "SELECT SUM(steps) as DayTotalSteps FROM dat WHERE steps IS NOT NULL GROUP BY date"
hist_dat <- sqldf(sql_statement)
ggplot(data = hist_dat, aes(hist_dat$DayTotalSteps)) + geom_histogram() + geom_vline(xintercept = 10766.19) + annotate("text", x = 10700, y = 9.4, label = "Mean = 10766.19, Median = 10765")
```
### 3. Calculate and report the mean and median of the total number of steps taken per day
The mean of the total number of steps taken per day is 10766.19.
```{r, echo=TRUE}
MeanTotalStepsPerDay
```
The median of the total number of steps taken per day is 10765.
```{r, echo=TRUE}
median(hist_dat$DayTotalSteps)
```
## What is the average daily activity pattern?
For this section of the project, we continue to ignore NA values (since the following involves imputing those missing values). Again, plot "window dressing" is left for another time.
### 1. Make a time series plot (i.e. ?????????? = "????") of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all days (y-axis)
```{r, echo=TRUE}
sql_statement <- "SELECT 1.0 * SUM(steps)/COUNT(1) AS [IntervalMeanSteps], interval FROM dat WHERE steps IS NOT NULL GROUP BY interval"
plot_dat <- sqldf(sql_statement)
ggplot(data = plot_dat, aes(x = plot_dat$interval, y = plot_dat$IntervalMeanSteps, group = 1)) + geom_line()
```
### 2. Which 5-minute interval, on average across all the days in the dataset, contains the maximum number of steps?
Interval 835 contains the maximum number of steps, on average, across all the days in the dataset: 206.1698 steps.
```{r, echo=TRUE}
sql_statement <- "SELECT interval AS [Interval of Max Mean Steps], IntervalMeanSteps AS [Max Mean Steps] FROM plot_dat WHERE IntervalMeanSteps = (SELECT MAX(IntervalMeanSteps) from plot_dat)"
sqldf(sql_statement)
```
## Imputing missing values
There are a number of days/intervals where there are missing values (coded as ????). The presence of missing days may introduce bias into some calculations or summaries of the data.
### 1. Calculate and report the total number of missing values in the dataset
```{r, echo=TRUE}
sql_statement <- "SELECT COUNT(1) AS [Number of NA Values] FROM dat WHERE steps IS NULL"
sqldf(sql_statement)
```
### 2. Devise a strategy for filling in all of the missing values in the dataset
Here, we will use the suggested strategy of replacing NA values with the mean number of steps for the corresponding interval. The reason for this choice over replacing with a day's mean is that some days consist entirely of NA data points. In the future, we may use a function of surrounding time intervals to calculate a particular NA's replacement value.
```{r, echo=TRUE}
sql_statement <- "SELECT interval, 1.0 * SUM(steps)/COUNT(1) MeanSteps FROM dat WHERE steps IS NOT NULL GROUP BY interval"
IntervalMeanSteps <- sqldf(sql_statement)
```
### 3. Create a new dataset that is equal to the original dataset but with the missing data filled in
```{r, echo=TRUE}
sql_statement <- "SELECT CASE WHEN steps IS NULL THEN IntervalMeanSteps.MeanSteps ELSE steps END AS StepsImpute, dat.date, dat.interval FROM dat LEFT JOIN IntervalMeanSteps ON dat.interval = IntervalMeanSteps.interval"
impute_dat <- sqldf(sql_statement)
```
A quick check of the original and new data sets:
```{r, echo=TRUE}
head(dat)
head(impute_dat)
```
### 4. Make a histogram of the total number of steps taken each day
We'll repeat some of the steps used above, generating the histogram for the data set with imputed values and reporting the new mean and median on the plot. The mean hasn't changed; however, the median is now equal to the mean and the shape of the histogram has changed (e.g., near the mode). In the days ahead, this calculation will be checked for correctness via alternate means.
```{r, echo=TRUE}
sql_statement <- "SELECT 1.0 * SUM(DayTotalImputeSteps)/COUNT(1) AS [Mean total number of steps (with imputation) taken per day] FROM (SELECT SUM(StepsImpute) as DayTotalImputeSteps FROM impute_dat GROUP BY date)"
MeanTotalImputeStepsPerDay <- sqldf(sql_statement)
MeanTotalImputeStepsPerDay
MedianTotalImputeStepsPerDay <- median(sqldf("SELECT SUM(StepsImpute) as DayTotalImputeSteps FROM impute_dat GROUP BY date")$DayTotalImputeSteps)
MedianTotalImputeStepsPerDay
sql_statement <- "SELECT SUM(StepsImpute) as DayTotalImputeSteps FROM impute_dat GROUP BY date"
hist_dat <- sqldf(sql_statement)
ggplot(data = hist_dat, aes(hist_dat$DayTotalImputeSteps)) + geom_histogram() + geom_vline(xintercept = 10766.19) + annotate("text", x = 10700, y = 12.4, label = "Mean = Median = 10766.19")
```
## Are there differences in activity patterns between weekdays and weekends?
### 1. Create a new factor variable in the dataset with two levels ?? ?eekday?? and ?eekend?? indicating whether a given date is a weekday or weekend day.
```{r, echo=TRUE}
impute_dat$date <- as.Date(impute_dat$date)
weekday <- c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday')
impute_dat$isWeekday <- factor((weekdays(impute_dat$date) %in% weekday), levels = c(FALSE, TRUE), labels = c('weekend', 'weekday'))
head(impute_dat)
```
### 2. Make a panel plot
In this step we make a panel plot containing a time series plot of the 5-minute interval (x-axis) and the average number of steps taken, averaged across all weekday days or weekend days (y-axis). There appears to be a difference in the subjects activity between weekday and weekend days. The large weekday peak near interval 860 compared to the remaining day's lower degree of activity contrasts to the more uniform nature of the weekend activity. There doesn't appear to be as clear a maximum for weekend intervals, when inspecting visually.
```{r, echo=TRUE}
sql_statement <- "SELECT 1.0 * SUM(StepsImpute)/COUNT(1) AS [IntervalMeanImputeSteps], interval, isWeekday FROM impute_dat GROUP BY interval, isWeekday"
plot_dat <- sqldf(sql_statement)
ggplot(data = plot_dat, aes(x = plot_dat$interval, y = plot_dat$IntervalMeanImputeSteps, group = 1)) + geom_line(color="firebrick",lwd = 1) + facet_wrap(~isWeekday, ncol = 1)
```
install.packages("markdown")
install.packages("PlotPrjNetworks")
install.packages("plot3D")
install.packages("data.table")
install.packages("data.tree")
install.packages("dataframes2xls")
install.packages("dataQualityR")
install.packages("datautils")
install.packages("dataview")
install.packages("datamap")
install.packages("igraph")
install.packages("rgl")
install.packages("ggvis")
install.packages("Stat2Data")
install.packages("statcheck")
install.packages("knitcitations")
install.packages("knitr")
install.packages("xtable")
install.packages("xlsx")
install.packages("XLConnect")
install.packages("connect3")
sessionInfo()
library(swirl)
swirl()
fit <- lm( child ~ parent, galton)
sqrt(sum(fit$residuals^2)/(n-2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum(mu^2)
sTot <- sum((galton$child - mu)^2)
sRes <- deviance(fit)
1-sRes/sTot
summary(fit)$r.squrared
summary(fit)$r.squared
cor(galton$parent, galton$child)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton
)
lm(child ~ 1, galton)
view(trees)
head(trees)
fit <- lm(Volume ~ + Height + Constant -1, trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
swirl()
library(swirl)
swirl()
all <- lm(Fertility ~ . , swiss)
summary(all)
summary(lm(Fertility ~ agriculture, swiss))
summary(lm(Fertility ~ Agriculture, swiss))
cor(Examination, Education)
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- sum(swiss$Examination, swiss$Catholic)
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility ~ . + ec, swiss)
all$coefficients - efit$coefficients
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)
fit <- lm(mpg ~ weight, mtcars)
summary(fit)
fit <- lm(mtcarts$mpg ~ mtcars$weight, mtcars)
x <- mtcars$wt
y <- mtcars$mpg
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x, mtcars)
summary(fit)
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x, mtcars)
summary(fit)
predict(fit,data.frame(x=mean(x)), interval="confidence")
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x, mtcars)
summary(fit)
predict(fit,data.frame(x=mean(x)), interval="confidence")
p1<-predict(fit,data.frame(x), interval="confidence")
plot(x,y,xlab='Weight (1000lb)',ylab='MPG')
abline(fit,col="red")
lines(x,p1[,2],col="purple")
lines(x,p1[,3],col="purple")
predict(fit,data.frame(x=3), interval="prediction")
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x, mtcars)
summary(fit)
predict(fit,data.frame(x=mean(x)), interval="confidence")
predict(fit,data.frame(x=3), interval="prediction")
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x, mtcars)
confint(fit)[2, ] * 2 #-12.973
##     2.5 %    97.5 %
## -12.97262  -8.40527
summary(fit)
fit2<-lm(y~I(x/2))
tbl2<-summary(fit2)$coefficients
mn<-tbl2[2,1]      #mean is the estimated slope
std_err<-tbl2[2,2] #standard error
deg_fr<-fit2$df    #degree of freedom
#Two sides T-Tests
mn + c(-1,1) * qt(0.975,df=deg_fr) * std_err
## [1] -12.973  -8.405
par(mfrow=c(1,2))
plot(x,y)
abline(fit,col="red")
plot(x/2,y)
abline(fit2,col="red")
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x, mtcars)
confint(fit)[2, ] * 2
summary(fit)
fit <- lm(y ~ x, mtcars)
fit1 <- lm(y ~ x, mtcars)
fit2 <- lm(y ~ 1, mtcars)
1 - summary(fit1)$r.squared
x <- mtcars$wt
y <- mtcars$mpg
fit <- lm(y ~ x, mtcars)
1 - summary(fit)$r.squared
install.packages("GGally")
install.packages("ggparallel")
library(swirl)
swirl()
library(swirl)
swirl()
install.packages("dplyr")
install.packages("latticeExtra")
install.packages("rgl")
install.packages("rglwidget")
install.packages("Rglpk")
install.packages("rglobi")
install.packages("influenceR")
install.packages("influence.ME")
install.packages("car")
install.packages("connect3")
install.packages("ggplot2movies")
install.packages("munsell")
library(swirl)
ls()
rm(list=ls())
ls()
library(swirl)
swirl()
6
dim(InsectSprays)
head(InsectSprays)
head(InsectSprays, 15)
sD
summary(InsectSprays[,2])
sapply(InsectSprays, class)
fit <- lm(count ~ spray, InsectSprays)
summary(fit)$coef
est <- fit$coef[,1]
est <- fit[,1$coe
f
est <- fit[,1]$coef
est <- summery(fit)$coef[,1]
est <- summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit <- lm(count ~ spray -1, InsectSprays)
summary(nfit)$coef
spray2 <- relevel(InsectSprays$spray, "C")
fit2 <- lm(count ~ spray2, InsectSprays )
summary(fit2)$coef
mean(sC)
(fit$coef[2]-fit$coef[3])/1.6011
libarary(swirl)
library(swirl)
swirl()
dim(hunger)
948
names(hunger)
fit <- lm(Numeric ~ Year, hunger)
summary(fit)$coef
lmF <- lm(hunger[hunger$Sex == "Female"] ~ year, hunger)
lmF <- lm(hunger$Numeric[hunger$Sex == "Female"] ~ hunger$Year[hunger$Sex == "Female"])
lmM <- lm(hunger$Numeric[hunger$Sex == "Male"] ~ hunger$Year[hunger$Sex == "Male"])
lmBoth <- lm(hunger$Numberic ~ hunger$Year + hunger$Sex)
lmBoth <- lm(Numberic ~ hunger$Year + hunger$Sex, hunger)
lmBoth <- lm(hunger$Numberic ~ hunger$Year + hunger$Sex)
lmBoth <- lm(hunger$Numeric ~ hunger$Year + hunger$Sex)
summary(lmBoth)
lmInter <- lm(numeric ~ Year + Sex +Sex*Year, hunger)
lmInter <- lm(Numeric ~ Year + Sex +Sex*Year, hunger)
summary(lmInter)
fit <- lm(y ~ x, out2)
plot(fit, which = 1)
fitno <- out2[-1,]
fitno <- lm(y ~ x, out2[-1,])
plot(fitno, which = 1)
coef(fit) - coef(fitno)
View(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
View(hatvalues(fit))
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which = 3)
plot(fit, which = 2)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
View(rstudent(fit))
dy <- predict(fitno, out2) - predict(fit, out2)
sum(dy^2)/(2*sigma^2)
plot(fit, which = 5)
install.packages("echart")
if (! 'recharts' %in% installed.packages()[,1]){
install.packages('recharts',
repos = c('http://yihui.name/xran', 'http://cran.rstudio.com')
)
}
dim(mtcars)
names(mtcars)
head(mtcars)
fit <- lm(mpg ~ cyl + wt, mtcars)
summary(fit)$coef
summary(fit)$coef[3,1]
cyl48 <- model.matrix(~cyl, mtcars)
fit <- lm(mpg ~ cyl48 + wt, mtcars)
summary(fit)$coef
fit <- lm(mpg ~ wt + cyl48, mtcars)
summary(fit)$coef
fit <- lm(mpg ~ wt + as.factor(cyl), mtcars)
summary(fit)$coef
dim(mtcars)
names(mtcars)
head(mtcars)
## cyl48 <- model.matrix(~cyl, mtcars)
## fit <- lm(mpg ~ cyl48 + wt, mtcars)
## summary(fit)$coef
fit <- lm(mpg ~ wt + as.factor(cyl), mtcars)
summary(fit)$coef
rm(list=ls())
ls()
dim(mtcars)
names(mtcars)
head(mtcars)
## cyl48 <- model.matrix(~cyl, mtcars)
## fit <- lm(mpg ~ cyl48 + wt, mtcars)
## summary(fit)$coef
fit <- lm(mpg ~ wt + as.factor(cyl), mtcars)
summary(fit)$coef
dim(mtcars)
names(mtcars)
head(mtcars)
## cyl48 <- model.matrix(~cyl, mtcars)
## fit <- lm(mpg ~ cyl48 + wt, mtcars)
## summary(fit)$coef
fit <- lm(mpg ~ wt + as.factor(cyl), mtcars)
summary(fit)$coef
fit <- lm(mpg ~ as.factor(cyl) + wt, mtcars)
summary(fit)$coef
fit <- lm(mpg ~ as.factor(cyl) + wt, mtcars)
summary(fit)$coef
fitwithout <- lm(mpg ~ as.factor(cyl), mtcars)
summary(fitwithout)$coef
install.packages("lmtest")
dim(mtcars)
names(mtcars)
head(mtcars)
## cyl48 <- model.matrix(~cyl, mtcars)
## fit <- lm(mpg ~ cyl48 + wt, mtcars)
## summary(fit)$coef
fit <- lm(mpg ~ as.factor(cyl) + wt, mtcars)
summary(fit)$coef
fitInteract <- lm(mpg ~ as.factor(cyl) + wt +cyl:wt, mtcars)
summary(fitwithout)$coef
fit <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fit)$coef
dim(mtcars)
names(mtcars)
head(mtcars)
fit <- lm(mpg ~ wt + factor(cyl), data = mtcars)
summary(fit)$coef
fit1 <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(fit1)$coef
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
outcome <- lm.influence(fit)
summary(outcome)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
outcome <- lm.influence(fit)
summary(outcome)
summary(outcome)$hat
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
lm.influence(fit)$hat
##outcome <- lm.influence(fit)
##summary(outcome)
##summary(outcome)$hat
dbbetas(fit)
dfbetas(fit)
install.packages("cacher")
